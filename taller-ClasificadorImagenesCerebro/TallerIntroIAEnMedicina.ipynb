{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lkeQcPkxK9q"
      },
      "source": [
        "### **Introducción a la Inteligencia Artificial en Medicina**\n",
        "Taller dictado por iHEALTH\n",
        "\n",
        "Recuerda ejecutar **TODAS** las celdas en orden"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.- Descargamos librerías y datos"
      ],
      "metadata": {
        "id": "J9pU5XSrBtzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"monai-weekly[pillow, tqdm]\"\n",
        "!pip install -q matplotlib\n",
        "%matplotlib inline\n",
        "import monai\n",
        "import matplotlib\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.data import decollate_batch, DataLoader\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    EnsureChannelFirst,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandFlip,\n",
        "    RandRotate,\n",
        "    RandZoom,\n",
        "    ScaleIntensity,\n",
        "    RandGaussianSmooth,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "from tabulate import tabulate\n",
        "\n",
        "print_config()\n",
        "\n",
        "_dummy_arr = torch.rand(1, device='cuda')\n",
        "\n",
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(f\"Root dir: {root_dir}\")\n",
        "\n",
        "#!gdown 1Ig45opmPavH_WgJiGBVV446LbqFfUAEd\n",
        "!gdown 1KXyvsXOTwa4Oi2A9Cee26hFMqALbPI7y\n",
        "!unzip -q -o /content/BDCerebroS.zip\n",
        "#!gdown 170rGaBqXh5mWagnmEMkbkLGZPdE0JS3a\n"
      ],
      "metadata": {
        "id": "aechIweGwyuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy-coRIdxK9t"
      },
      "source": [
        "## 2.- Revisar las imágenes de la base de datos\n",
        "\n",
        "Primero verificaremos las estadísticas de la base de datos.\n",
        "\n",
        "Tenemos 4 carpetas en la base de datos: glioma, meningioma, pituitaria y notumor.\n",
        "\n",
        "Estos nombres de las carpetas serán las clases para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IjdmTmFqxK9t"
      },
      "outputs": [],
      "source": [
        "carpetaBD=\"BDCerebro\"\n",
        "nombres_clases = sorted(x for x in os.listdir(carpetaBD) if os.path.isdir(os.path.join(carpetaBD, x)))\n",
        "cantidad_clases = len(nombres_clases)\n",
        "archivos_imagenes = [\n",
        "    [os.path.join(carpetaBD, nombres_clases[i], x) for x in os.listdir(os.path.join(carpetaBD, nombres_clases[i]))]\n",
        "    for i in range(cantidad_clases)\n",
        "]\n",
        "conteo_clase = [len(archivos_imagenes[i]) for i in range(cantidad_clases)]\n",
        "lista_archivos_imagenes = []\n",
        "clase_imagen = []\n",
        "for i in range(cantidad_clases):\n",
        "    lista_archivos_imagenes.extend(archivos_imagenes[i])\n",
        "    clase_imagen.extend([i] * conteo_clase[i])\n",
        "num_total = len(clase_imagen)\n",
        "image_width, image_height = PIL.Image.open(lista_archivos_imagenes[0]).size\n",
        "\n",
        "print(f\"Cantidad total de imágenes: {num_total}\")\n",
        "print(f\"Dimensiones imágenes: {image_width} x {image_height}\")\n",
        "print(f\"Nombres de las clases: {nombres_clases}\")\n",
        "print(f\"Imágenes por clase: {conteo_clase}\")\n",
        "\n",
        "plt.subplots(3, 3, figsize=(8, 8))\n",
        "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
        "    im = PIL.Image.open(lista_archivos_imagenes[k])\n",
        "    arr = np.array(im)\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.xlabel(nombres_clases[clase_imagen[k]])\n",
        "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5De4-6VexK9u"
      },
      "source": [
        "## 3.- Preparación de la lista de entrenamiento, validación y testeo\n",
        "\n",
        "Elegimos aleatoreamente el 10% de la base de datos para validación y otro 10% para testeo. El 80% restante se usará para entrenar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "iyTt-oxWxK9u"
      },
      "outputs": [],
      "source": [
        "fraccion_validacion = 0.15\n",
        "fraccion_testeo = 0.15\n",
        "conteo_imagenes = len(lista_archivos_imagenes)\n",
        "indices = np.arange(conteo_imagenes)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "test_split = int(fraccion_testeo * conteo_imagenes)\n",
        "val_split = int(fraccion_validacion * conteo_imagenes) + test_split\n",
        "test_indices = indices[:test_split]\n",
        "val_indices = indices[test_split:val_split]\n",
        "train_indices = indices[val_split:]\n",
        "\n",
        "train_x = [lista_archivos_imagenes[i] for i in train_indices]\n",
        "train_y = [clase_imagen[i] for i in train_indices]\n",
        "val_x = [lista_archivos_imagenes[i] for i in val_indices]\n",
        "val_y = [clase_imagen[i] for i in val_indices]\n",
        "test_x = [lista_archivos_imagenes[i] for i in test_indices]\n",
        "test_y = [clase_imagen[i] for i in test_indices]\n",
        "\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        ScaleIntensity(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
        "\n",
        "y_pred_trans = Compose([Activations(softmax=True)])\n",
        "y_trans = Compose([AsDiscrete(to_onehot=cantidad_clases)])\n",
        "\n",
        "class MedNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, archivos_imagenes, labels, transforms):\n",
        "        self.archivos_imagenes = archivos_imagenes\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.archivos_imagenes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transforms(self.archivos_imagenes[index]), self.labels[index]\n",
        "\n",
        "\n",
        "train_ds = MedNISTDataset(train_x, train_y,train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=20, shuffle=True, num_workers=2)\n",
        "\n",
        "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=20, num_workers=2)\n",
        "\n",
        "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=20, num_workers=2)\n",
        "\n",
        "print(f\"Imágenes de entrenamiento: {len(train_x)}, Imágenes de validación: \" f\"{len(val_x)}, Imágenes de testeo: {len(test_x)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoZCgSuMxK9u"
      },
      "source": [
        "## 4.- Definimos la red y el optimizador\n",
        "\n",
        "1. Fijamos el learning rate que define qué tanto se modifica nuestro modelo por batch.\n",
        "1. Fijamos la cantidad de épocas de entrenamiento, así como las transformaciones que requiere la imagen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvj09dvJxK9u"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=cantidad_clases).to(device)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "max_epocas = 5\n",
        "val_interval = 1\n",
        "auc_metric = ROCAUCMetric()\n",
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOmkCAwJxK9u"
      },
      "source": [
        "## 5.- Entrenamiento del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WJ1kRn8jxK9u"
      },
      "outputs": [],
      "source": [
        "assert root_dir and os and torch and model, \"Recuerda correr todas las celdas anteriores\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "mejor_metrica = -1\n",
        "mejor_metrica_epoca = -1\n",
        "epoca_loss_values = []\n",
        "metric_values = []\n",
        "\n",
        "fig = plt.figure()\n",
        "current_loss = 1\n",
        "losses = []\n",
        "plt.axis([0, 10, 0, 1])\n",
        "n_steps = 36*max_epocas\n",
        "plt.ylim(0, 1.4)\n",
        "plt.xlim(0, n_steps)\n",
        "plt.title(\"Pérdida por paso\")\n",
        "plt.xlabel(\"paso\")\n",
        "plt.ylabel(\"pérdida\")\n",
        "\n",
        "for epoca in range(max_epocas):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoca {epoca + 1}/{max_epocas}\")\n",
        "    model.train()\n",
        "    epoca_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoca_loss += loss.item()\n",
        "        #print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"función de pérdida: {loss.item():.4f}\")\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        plt.plot(np.arange(len(losses)), losses, color='blue')\n",
        "        display(fig)\n",
        "        clear_output(wait=True)\n",
        "\n",
        "\n",
        "        epoca_len = len(train_ds) // train_loader.batch_size\n",
        "    epoca_loss /= step\n",
        "    epoca_loss_values.append(epoca_loss)\n",
        "    #print(f\"época {epoca + 1} pérdida promedio: {epoca_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    if (epoca + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:\n",
        "                val_images, val_labels = (\n",
        "                    val_data[0].to(device),\n",
        "                    val_data[1].to(device),\n",
        "                )\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
        "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
        "            auc_metric(y_pred_act, y_onehot)\n",
        "            result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(result)\n",
        "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
        "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
        "            if result > mejor_metrica:\n",
        "                mejor_metrica = result\n",
        "                mejor_metrica_epoca = epoca + 1\n",
        "                torch.save(model.state_dict(), os.path.join(root_dir, \"mejor_metrica_model.pth\"))\n",
        "\n",
        "plt.show()\n",
        "print(\"\\nEntrenamiento completado\")\n",
        "print(f\"mejor métrica: {mejor_metrica:.4f} \" f\" en la época: {mejor_metrica_epoca}\")\n",
        "\n",
        "plt.figure(\"entrenamiento\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Pérdida promedio por época \")\n",
        "x = [i + 1 for i in range(len(epoca_loss_values))]\n",
        "y = epoca_loss_values\n",
        "plt.xlabel(\"época\")\n",
        "plt.ylabel(\"pérdida\")\n",
        "plt.xticks(np.arange(len(epoca_loss_values)) + 1)\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Acierto en validación\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"época\")\n",
        "plt.xticks(np.arange(len(metric_values)) + 1)\n",
        "plt.ylabel(\"Acierto\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPoZ4tCbxK9v"
      },
      "source": [
        "## 6.- Evaluación de los resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path_dir = os.path.join(root_dir, \"mejor_metrica_model.pth\")\n",
        "# model_path_dir = '/content/mejor_metrica_model_epoch10.pth'\n",
        "\n",
        "model.load_state_dict(torch.load(model_path_dir))\n",
        "_ = model.eval()\n",
        "\n",
        "\n",
        "n_test_samples = 4\n",
        "images, labels = tuple(zip(*[\n",
        "    test_ds[idx]\n",
        "    for idx in np.random.randint(len(test_ds), size=n_test_samples)\n",
        "]))\n",
        "images = torch.stack(images).to(device)\n",
        "labels = np.array(labels)\n",
        "\n",
        "with torch.no_grad():\n",
        "  preds = model(images.cuda()).argmax(dim=1)\n",
        "\n",
        "images = images.squeeze(1).cpu().numpy()\n",
        "preds = preds.cpu().numpy()\n",
        "plt.subplots(1, n_test_samples, figsize=(8, 8))\n",
        "for i, (image, pred, label) in enumerate(zip(images, preds, labels)):\n",
        "    plt.subplot(n_test_samples, n_test_samples, i + 1)\n",
        "    plt.xlabel(f\"Predicción: {nombres_clases[pred]}\\nReal: {nombres_clases[label]}\")\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0BbYGsc4Rmoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.- Resumen de los resultados\n",
        "\n"
      ],
      "metadata": {
        "id": "cxkTsh6-rChl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB4czqVhxK9v"
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for test_data in test_loader:\n",
        "        test_images, test_labels = (\n",
        "            test_data[0].to(device),\n",
        "            test_data[1].to(device),\n",
        "        )\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())\n",
        "\n",
        "data = np.array([nombres_clases,precision_score(y_true, y_pred, average=None), recall_score(y_true, y_pred, average=None)])\n",
        "data =np.transpose(data)\n",
        "\n",
        "col_names = [\"Clase\",\"Precisión\",\"Exhaustividad\"]\n",
        "\n",
        "print(tabulate(data, headers=col_names))\n",
        "\n",
        "print(\"\\nAcierto total: \", accuracy_score(y_true, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.- Bonus: Aumentación de datos\n",
        "\n",
        "Aplicamos transformaciones a las imágenes para tener más datos de entrenamiento"
      ],
      "metadata": {
        "id": "yPdwjxW0sgPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        ScaleIntensity(),\n",
        "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
        "        RandFlip(spatial_axis=0, prob=0.5),\n",
        "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
        "\n",
        "y_pred_trans = Compose([Activations(softmax=True)])\n",
        "y_trans = Compose([AsDiscrete(to_onehot=cantidad_clases)])\n",
        "\n",
        "class MedNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, archivos_imagenes, labels, transforms):\n",
        "        self.archivos_imagenes = archivos_imagenes\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.archivos_imagenes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transforms(self.archivos_imagenes[index]), self.labels[index]\n",
        "\n",
        "\n",
        "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=20, shuffle=True, num_workers=2)\n",
        "\n",
        "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=20, num_workers=2)\n",
        "\n",
        "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=20, num_workers=2)\n",
        "plt.subplots(2, 3, figsize=(12, 8))\n",
        "image, _ = train_ds[np.random.randint(len(train_ds))]\n",
        "\n",
        "def plot_subplot(image, plot_idx, title):\n",
        "  plt.subplot(2, 3, plot_idx)\n",
        "  plt.imshow(image.squeeze(0), cmap=\"gray\")\n",
        "  plt.xlabel(title)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "plot_subplot(image, 1, \"Original\")\n",
        "plot_subplot(ScaleIntensity(minv=0.1, maxv=20)(image), 2, \"Intensidad\")\n",
        "plot_subplot(RandRotate(range_x=np.pi / 2, prob=1, keep_size=True)(image), 3, \"Rotada\")\n",
        "plot_subplot(RandFlip(spatial_axis=1, prob=1)(image), 4, \"Flip\")\n",
        "plot_subplot(RandZoom(min_zoom=0.4, max_zoom=1.6, prob=1)(image), 5, \"Zoom\")\n",
        "plot_subplot(RandRotate(range_x=np.pi / 2, prob=1, keep_size=True)(RandZoom(min_zoom=0.4, max_zoom=1.6, prob=1)(image)), 6, \"Zoom Rotada\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pv2A7xpDsoQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9XnD-3_xK9o"
      },
      "source": [
        "Este tutorial fue realizado en base a **Medical Image Classification Tutorial with the MedNIST Dataset** Copyright (c) MONAI Consortium  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}